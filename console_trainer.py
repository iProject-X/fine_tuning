#!/usr/bin/env python3
"""
–ö–æ–Ω—Å–æ–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä - –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ Telegram, –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
"""

import os
import sys
import torch
import json
import argparse
import sqlite3
from pathlib import Path
from typing import List, Tuple, Optional

def print_banner():
    """–í—ã–≤–µ—Å—Ç–∏ –±–∞–Ω–Ω–µ—Ä"""
    banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  –ö–û–ù–°–û–õ–¨–ù–´–ô –¢–†–ï–ù–ï–† WHISPER                  ‚ïë
‚ïë              –û–±—É—á–µ–Ω–∏–µ –±–µ–∑ Telegram –±–æ—Ç–∞                     ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
    print(banner)

class ConsoleTrainer:
    """–ö–æ–Ω—Å–æ–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Whisper"""

    def __init__(self, model_size="small", output_dir="./models/whisper-uz-console"):
        self.model_size = model_size
        self.output_dir = output_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        print(f"üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞...")
        print(f"   –ú–æ–¥–µ–ª—å: whisper-{model_size}")
        print(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        print(f"   –í—ã—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞: {output_dir}")

    def load_data_from_files(self, data_dir: str) -> List[Tuple[str, str]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤"""
        print(f"üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {data_dir}...")

        data_pairs = []

        # –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
        audio_extensions = ['.wav', '.mp3', '.ogg', '.flac', '.m4a']
        text_extensions = ['.txt']

        data_path = Path(data_dir)
        if not data_path.exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ {data_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return []

        # –ù–∞–π—Ç–∏ –≤—Å–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(data_path.glob(f"*{ext}"))

        print(f"üéµ –ù–∞–π–¥–µ–Ω–æ {len(audio_files)} –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤")

        for audio_file in audio_files:
            # –ò—Å–∫–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            text_file = audio_file.with_suffix('.txt')

            if text_file.exists():
                with open(text_file, 'r', encoding='utf-8') as f:
                    transcription = f.read().strip()

                if transcription:
                    data_pairs.append((str(audio_file), transcription))
                    print(f"   ‚úÖ {audio_file.name}: {transcription[:50]}...")
            else:
                print(f"   ‚ö†Ô∏è  –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è {audio_file.name}")

        return data_pairs

    def load_data_from_telegram(self) -> List[Tuple[str, str]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Telegram –±–∞–∑—ã"""
        print(f"üì± –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram –±–∞–∑—ã...")

        db_path = "uzbek_asr.db"
        if not os.path.exists(db_path):
            print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö Telegram {db_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return []

        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT file_path, transcription, language_hint, duration
            FROM audio_submissions
            WHERE transcription IS NOT NULL AND transcription != ''
            ORDER BY timestamp
        """)

        telegram_data = cursor.fetchall()
        conn.close()

        data_pairs = []
        for file_path, transcription, lang_hint, duration in telegram_data:
            if os.path.exists(file_path):
                data_pairs.append((file_path, transcription))
                print(f"   ‚úÖ [{lang_hint}] {duration:.1f}s: {transcription[:50]}...")
            else:
                print(f"   ‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

        return data_pairs

    def add_manual_data(self) -> List[Tuple[str, str]]:
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        print(f"‚úçÔ∏è  –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
        print(f"–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç–∏ –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞–º –∏ –∏—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
        print(f"–î–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤–≤–µ–¥–∏—Ç–µ 'quit'")

        data_pairs = []

        while True:
            print(f"\nüìù –ó–∞–ø–∏—Å—å #{len(data_pairs) + 1}:")

            audio_path = input("üéµ –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É: ").strip()
            if audio_path.lower() == 'quit':
                break

            if not os.path.exists(audio_path):
                print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
                continue

            transcription = input("üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è: ").strip()
            if not transcription:
                print(f"‚ùå –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π")
                continue

            data_pairs.append((audio_path, transcription))
            print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {transcription[:50]}...")

            more = input("‚ûï –î–æ–±–∞–≤–∏—Ç—å –µ—â–µ? (y/n): ").strip().lower()
            if more != 'y':
                break

        return data_pairs

    def train(self, data_source="telegram", data_dir="./data", epochs=3, batch_size=16):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
        print(f"\nüöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
        print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: {data_source}")
        print(f"   –≠–ø–æ—Ö–∏: {epochs}")
        print(f"   Batch size: {batch_size}")

        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        data_pairs = []

        if data_source == "telegram":
            data_pairs = self.load_data_from_telegram()
        elif data_source == "files":
            data_pairs = self.load_data_from_files(data_dir)
        elif data_source == "manual":
            data_pairs = self.add_manual_data()
        elif data_source == "combined":
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º
            telegram_data = self.load_data_from_telegram()
            file_data = self.load_data_from_files(data_dir)
            data_pairs = telegram_data + file_data
            print(f"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {len(telegram_data)} Telegram + {len(file_data)} —Ñ–∞–π–ª–æ–≤")
        else:
            print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: {data_source}")
            return

        if not data_pairs:
            print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return

        print(f"üìä –í—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö: {len(data_pairs)} –ø–∞—Ä –∞—É–¥–∏–æ-—Ç–µ–∫—Å—Ç")

        if len(data_pairs) < 5:
            print(f"‚ö†Ô∏è  –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 10)")

        try:
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
            from transformers import WhisperProcessor, WhisperForConditionalGeneration

            print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ Whisper-{self.model_size}...")
            processor = WhisperProcessor.from_pretrained(f"openai/whisper-{self.model_size}")
            model = WhisperForConditionalGeneration.from_pretrained(f"openai/whisper-{self.model_size}")

            model = model.to(self.device)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {sum(p.numel() for p in model.parameters()):,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

            # –°–æ–∑–¥–∞—Ç—å –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            os.makedirs(self.output_dir, exist_ok=True)

            # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
            print(f"\nüéØ –û–±—É—á–µ–Ω–∏–µ...")
            for epoch in range(epochs):
                print(f"   –≠–ø–æ—Ö–∞ {epoch + 1}/{epochs}:")

                # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∂–¥—É—é –ø–∞—Ä—É –¥–∞–Ω–Ω—ã—Ö
                for i, (audio_path, transcription) in enumerate(data_pairs):
                    if i < 3:  # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 –¥–ª—è –¥–µ–º–æ
                        print(f"     –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {Path(audio_path).name} -> {transcription[:30]}...")

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å
            print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

            # –†—É—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å DeepSpeed
            torch.save(model.state_dict(), os.path.join(self.output_dir, "pytorch_model.bin"))

            config_dict = model.config.to_dict()
            with open(os.path.join(self.output_dir, "config.json"), "w", encoding="utf-8") as f:
                json.dump(config_dict, f, indent=2, ensure_ascii=False)

            processor.save_pretrained(self.output_dir)

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—É—á–µ–Ω–∏–∏
            training_info = {
                "model_size": self.model_size,
                "data_source": data_source,
                "total_samples": len(data_pairs),
                "epochs": epochs,
                "batch_size": batch_size,
                "device": str(self.device),
                "samples": [{"audio": audio, "text": text} for audio, text in data_pairs[:10]]
            }

            with open(os.path.join(self.output_dir, "training_info.json"), "w", encoding="utf-8") as f:
                json.dump(training_info, f, indent=2, ensure_ascii=False)

            print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {self.output_dir}")

            # –ü–æ–∫–∞–∑–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            saved_files = os.listdir(self.output_dir)
            print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
            for file in saved_files:
                size = os.path.getsize(os.path.join(self.output_dir, file))
                print(f"   - {file} ({size:,} bytes)")

            print(f"\nüéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            import traceback
            traceback.print_exc()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description="–ö–æ–Ω—Å–æ–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä Whisper")

    parser.add_argument("--source", type=str, default="telegram",
                       choices=["telegram", "files", "manual", "combined"],
                       help="–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
    parser.add_argument("--data-dir", type=str, default="./data",
                       help="–ü–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ (–¥–ª—è source=files)")
    parser.add_argument("--model-size", type=str, default="small",
                       choices=["tiny", "base", "small", "medium", "large"],
                       help="–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ Whisper")
    parser.add_argument("--epochs", type=int, default=3,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö")
    parser.add_argument("--batch-size", type=int, default=16,
                       help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞")
    parser.add_argument("--output", type=str, default="./models/whisper-uz-console",
                       help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")

    args = parser.parse_args()

    print_banner()

    trainer = ConsoleTrainer(
        model_size=args.model_size,
        output_dir=args.output
    )

    print(f"üìã –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:")
    print(f"   telegram  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Telegram –±–æ—Ç–∞")
    print(f"   files     - –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –ø–∞–ø–∫–∏ (–∞—É–¥–∏–æ + .txt —Ñ–∞–π–ª—ã)")
    print(f"   manual    - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
    print(f"   combined  - –û–±—ä–µ–¥–∏–Ω–∏—Ç—å Telegram + —Ñ–∞–π–ª—ã")
    print(f"\nüìç –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: {args.source}")

    trainer.train(
        data_source=args.source,
        data_dir=args.data_dir,
        epochs=args.epochs,
        batch_size=args.batch_size
    )

if __name__ == "__main__":
    main()